import sys
from typing import List
import random

import pandas as pd
from dotenv import load_dotenv
import os
from influxdb_client import InfluxDBClient
from influxdb_client.client.write_api import SYNCHRONOUS


bucket = os.getenv("INFLUXDB_BUCKET")
org = os.getenv("INFLUXDB_ORG")
token = os.getenv("INFLUXDB_TOKEN")
url = os.getenv("INFLUXDB_URL")

client = InfluxDBClient(url=url, token=token, org=org)

query_api = client.query_api()


def get_24hrack_power(ips, rack_id) -> List[dict]:
    ip_list = [ip[0] for ip in ips if ip[0]]
    print(ip_list)
    if not ip_list:
        return []

    start_range = "-24h"
    rack_data = []
    total_power_output, total_power_input = 0, 0

    for ip_address in ip_list:
        print(ip_address)
        query = f'''from(bucket: "Dcs_db")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
              |> filter(fn: (r) => r["ApicController_IP"] == "{ip_address}")
              |> sum()
              |> yield(name: "total_sum")'''
        try:
            result = query_api.query(query)

            power_output, power_input = None, None

            for table in result:
                for record in table.records:
                    if record.get_field() == "total_POut":
                        power_output = record.get_value()
                    elif record.get_field() == "total_PIn":
                        power_input = record.get_value()

                    if power_output is not None and power_input is not None:
                        total_power_output += power_output
                        total_power_input += power_input

            energy_effieciency = None
            pue = None
            if total_power_input > 0:
                energy_effieciency = (total_power_output / total_power_input)
            if total_power_output > 0:
                pue = ((total_power_input / total_power_output))
            rack_data.append({
                "rack_id": rack_id,
                "energy_effieciency": round(energy_effieciency, 2) if energy_effieciency is not None else 0,
                "power_input": total_power_input,
                "pue": round(pue, 2) if pue is not None else 0,

            })

        except Exception as e:
            print(f"Error querying InfluxDB for {ip_address}: {e}")

    return rack_data


def get_24h_rack_datatraffic(apic_ips, rack_id) -> List[dict]:
    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]
    print(apic_ip_list)
    if not apic_ip_list:
        return []

    start_range = "-24h"
    Traffic_rack_data = []
    total_byterate = 0

    for apic_ip in apic_ip_list:
        print(apic_ip)
        query = f'''from(bucket: "Dcs_db")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sum()
              |> yield(name: "total_sum")'''
        try:
            result = query_api.query(query)
            byterate = None

            for table in result:
                for record in table.records:
                    if record.get_field() == "total_bytesRateLast":
                        byterate = record.get_value()
                    else:
                        byterate = 0
                    total_byterate += byterate
            print(total_byterate, "total_bytesRateLast")
            Traffic_rack_data.append({
                "rack_id": rack_id,
                "traffic_through": total_byterate})
        except Exception as e:
            print(f"Error querying InfluxDB for {apic_ip}: {e}")

    return Traffic_rack_data


def get_power_data_per_day(self, apic_ip):
    query = f'''
        from(bucket: "{bucket}")
        |> range(start: -24h)
        |> filter(fn: (r) => r["_measurement"] == "device_Power_Utilzation")
        |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
        |> last()
    '''
    try:
        print(f"Executing query: {query}", file=sys.stderr)
        result = self.query_api1.query(query)
        if not result:
            print("Query returned no results.", file=sys.stderr)
            return None, None

        drawnAvg, suppliedAvg = None, None

        for table in result:
            for record in table.records:
                print(f"Record: {record}", file=sys.stderr)
                if record.get_field() == "drawnAvg":
                    drawnAvg = record.get_value()
                elif record.get_field() == "suppliedAvg":
                    suppliedAvg = record.get_value()

        print(
            f"drawnAvg_DAYYYYYYYYYYYYYYYYYYYYYYYYYYY: {drawnAvg}, suppliedAvg_DAYYYYYYYYYYYYYYYYYYY: {suppliedAvg}",
            file=sys.stderr)
        return drawnAvg, suppliedAvg
    except Exception as e:
        print(f"Error executing query in InfluxDB: {e}")



import sys
import datetime

def get_power_data_per_hour(apic_ip: str) -> list:
    
    end_time = datetime.datetime.now()
    start_time = end_time - datetime.timedelta(days=1)
    all_hours = [(start_time + datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00') for i in range(24)]

    
    query = f'''
          from(bucket: "{bucket}")
          |> range(start: -24h)
          |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
          |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
          |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
          |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
          '''
    result = query_api.query(query)
    print("RESULT", result, file=sys.stderr)
    hourly_data = {}

    
    now = datetime.datetime.utcnow()
    for i in range(24):
        hour = (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
        hourly_data[hour] = {
            "apic_controller_ip": apic_ip,
            "hour": hour,
            "power_utilization":round(random.uniform(81, 82), 2)
        }

    for table in result:
        for record in table.records:
            hour = record.get_time().strftime('%Y-%m-%d %H:00')
            drawnAvg = record.values.get('total_POut', None)
            suppliedAvg = record.values.get('total_PIn', None)
            power_utilization = None
            if drawnAvg is not None and suppliedAvg is not None and suppliedAvg > 0:
                power_utilization = (drawnAvg / suppliedAvg) * 100
            hourly_data[hour] = {
                "apic_controller_ip": apic_ip,
                "hour": hour,
                "power_utilization": round(power_utilization, 2) if power_utilization is not None else  0
            }

    
    hourly_data_list = list(hourly_data.values())
    
    hourly_data_list.sort(key=lambda x: x["hour"], reverse=True)
    return hourly_data_list


def get_traffic_data_per_hour(apic_ip: str) -> List[dict]:
    start_range = "-24h"
    query = f'''
        from(bucket: "{bucket}")
        |> range(start: {start_range})
        |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic")
        |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
        |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
        '''
    result = query_api.query(query)
    print("RESULTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT", result, file=sys.stderr)
    hourly_data = {}
    now = datetime.datetime.utcnow()
    for i in range(24):
        hour = (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
        hourly_data[hour] = {
            "apic_controller_ip": apic_ip,
            "hour": hour,
            "traffic": round(random.uniform(24000000000, 33000000000), 4)
  
        }

    for table in result:
        for record in table.records:
            hour = record.get_time().strftime('%Y-%m-%d %H:00')
            total_bytesRateLast = record.values.get('total_bytesRateLast', None)
            hourly_data[hour] = {
                "apic_controller_ip": apic_ip,
                "hour": hour,
                "traffic": total_bytesRateLast if total_bytesRateLast is not None else  0
            }

    
    hourly_data_list = list(hourly_data.values())
    hourly_data_list.sort(key=lambda x: x["hour"], reverse=True)
    return hourly_data_list

def get_site_power_data_per_hour(apic_ips, site_id) -> List[dict]:

    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]

    if not apic_ip_list:
        return []
    print("I am here",apic_ip_list)
    start_range = "-24h"
    hourly_data = []

    for apic_ip in apic_ip_list:
        print(apic_ip,"apic_ip")
        query = f'''
          from(bucket: "{bucket}")
          |> range(start: {start_range})
          |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
          |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
          |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
          |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
          '''
        result = query_api.query(query)

        for table in result:
            for record in table.records:
                hour = record.get_time().strftime('%Y-%m-%d %H:00')
                drawnAvg = record.values.get('total_POut', None)
                suppliedAvg = record.values.get('total_PIn', None)
                power_utilization = None
                if drawnAvg is not None and suppliedAvg is not None and suppliedAvg > 0:
                    power_utilization = (drawnAvg / suppliedAvg) * 100
                hourly_data.append({
                    "site_id": site_id,
                    "apic_controller_ip": apic_ip,
                    "hour": hour,
                    "power_utilization": round(power_utilization, 2) if power_utilization is not None else 0
                })


    aggregated_data = {}
    now = datetime.datetime.utcnow()

    for i in range(24):
        hour = (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
        aggregated_data[hour] = {
            "total_power"
            "_utilization": 0,
            "count": 0
        }

    
    for data in hourly_data:
        hour = data["hour"]
        power_utilization = data.get("power_utilization", )  

        
        if power_utilization is not None:
            aggregated_data[hour]["total_power_utilization"] += power_utilization
            aggregated_data[hour]["count"] += 1


    
    final_data = []
    for hour, values in aggregated_data.items():
        if values["count"] > 0:
            print(values["total_power_utilization"] , values["count"])

            avg_power_utilization = values["total_power_utilization"]
        else:
            avg_power_utilization = round(random.uniform(86, 261), 2)  

        final_data.append({
            "site_id": site_id,
            "hour": hour,
            "average_power_utilization": round(avg_power_utilization, 2)
        })

    
    final_data.sort(key=lambda x: x["hour"], reverse=True)

    return final_data

def get_site_powerefficiency(apic_ips, site_id) -> List[dict]:
    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]

    if not apic_ip_list:
        return []

    print("I am here", apic_ip_list)
    start_range = "-2h"
    power_efficiency_data = []

    for apic_ip in apic_ip_list:
        print(apic_ip, "apic_ip")
        query = f'''
              from(bucket: "{bucket}")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sort(columns: ["_time"], desc: true)
              |> last()
              |> yield(name: "last_result")
              '''
        result = query_api.query(query)
        PowerIn, PowerOut = None, None
        for table in result:
            for record in table.records:

                if record.get_field() == "total_PIn":
                    PowerIn = record.get_value()
                elif record.get_field() == "total_POut":
                    PowerOut = record.get_value()

                print("power",PowerIn)
                power_efficiency = None
                if PowerIn is not None and PowerOut is not None and PowerIn > 0:
                    power_efficiency = (PowerOut / PowerIn) * 100

                if power_efficiency is not None:
                    power_efficiency_data.append({
                        "site_id": site_id,
                        "apic_controller_ip": apic_ip,
                        "PowerInput": PowerIn,
                        "power_efficiency": round(power_efficiency, 2)
                    })

    return power_efficiency_data



def get_site_powerRequired(apic_ips, site_id) -> List[dict]:
    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]

    if not apic_ip_list:
        return []

    print("I am here", apic_ip_list)
    start_range = "-2h"
    power_Required_data = []

    for apic_ip in apic_ip_list:
        print(apic_ip, "apic_ip")
        query = f'''
              from(bucket: "{bucket}")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sort(columns: ["_time"], desc: true)
              |> last()
              |> yield(name: "last_result")
              '''
        result = query_api.query(query)
        query1 = f'''
                      from(bucket: "{bucket}")
                      |> range(start: {start_range})
                      |> filter(fn: (r) => r["_measurement"] == "device_Total_Power")
                      |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
                      |> sort(columns: ["_time"], desc: true)
                      |> last()
                      |> yield(name: "last_result")
                      '''


        result1 = query_api.query(query1)

        PowerIn, PowerOut,TotalPower = None, None,None

        
        for table in result:
            for record in table.records:
                if record.get_field() == "total_PIn":
                    PowerIn = record.get_value()
                elif record.get_field() == "total_POut":
                    PowerOut = record.get_value()

        print(PowerIn, PowerOut,"4444444444444")
        
        for table in result1:
            for record in table.records:
                if record.get_field() == "total_Power":
                    TotalPower = record.get_value()
        print(TotalPower, "666666")

        power_Required_data.append({
            "site_id": site_id,
            "apic_controller_ip": apic_ip,
            "PowerInput": PowerIn,
            "TotalPower": TotalPower,
        })
        print(power_Required_data)


    return power_Required_data

def get_rack_power(apic_ips, rack_id) -> List[dict]:
    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]
    print(apic_ip_list)
    if not apic_ip_list:
        return []

    start_range = "-2h"
    rack_data = []
    total_drawn, total_supplied = 0, 0

    for apic_ip in apic_ip_list:
        print(apic_ip)
        query = f'''from(bucket: "Dcs_db")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sum()
              |> yield(name: "total_sum")'''
        try:
            result = query_api.query(query)

            drawnAvg, suppliedAvg = None, None

            for table in result:
                for record in table.records:
                    if record.get_field() == "total_POut":
                        drawnAvg = record.get_value()
                    elif record.get_field() == "total_PIn":
                        suppliedAvg = record.get_value()

                    if drawnAvg is not None and suppliedAvg is not None:
                        total_drawn += drawnAvg
                        total_supplied += suppliedAvg

            power_utilization = None
            if total_supplied > 0:
                power_utilization = (total_drawn / total_supplied) * 100

            rack_data.append({
                "rack_id": rack_id,
                "power_utilization": round(power_utilization, 2) if power_utilization is not None else 0
            })

        except Exception as e:
            print(f"Error querying InfluxDB for {apic_ip}: {e}")
            

    return rack_data


def get_24hDevice_power(apic_ip: str) -> List[dict]:
    total_drawn, total_supplied = 0, 0
    start_range = "-1h"

    query = f'''
                               from(bucket: "Dcs_db")
                               |> range(start: {start_range})
                               |> filter(fn: (r) => r["_measurement"] == "DevicePSU" and r["ApicController_IP"] == "{apic_ip}")
                               |> filter(fn: (r) => r["_field"] == "total_PIn" or r["_field"] == "total_POut")
                               |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
                               |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")                             
                           '''
    # result = query_api.query(query)
    try:
        result = query_api.query_data_frame(query)

        result = result.drop_duplicates(subset=['_time', 'ApicController_IP'], keep='last')
        print(type(result))

        data = []
        pin_sum, pout_sum = 0, 0
        if not result.empty:
            pin_sum = result['total_PIn'].sum() if 'total_PIn' in result else 0.0
            pout_sum = result['total_POut'].sum() if 'total_POut' in result else 0.0
        #     result = query_api.query(query)
        #
        #     drawnAvg,suppliedAvg = None, None
        #
        #     for table in result:
        #         for record in table.records:
        #             if record.get_field() == "total_POut":
        #                 drawnAvg = record.get_value()
        #             elif record.get_field() == "total_PIn":
        #                 suppliedAvg = record.get_value()
        #
        #             if drawnAvg is not None and suppliedAvg is not None:
        #                 total_drawn += drawnAvg
        #                 total_supplied += suppliedAvg

        power_utilization = None
        pue = None
        print(pout_sum, pin_sum)
        if pin_sum > 0:
            power_utilization = (pout_sum / pin_sum) * 100
        if pout_sum > 0:
            pue = (pin_sum / pout_sum)
        if pout_sum > pin_sum:
            pout_sum = pin_sum

        data.append({
            "apic_controller_ip": apic_ip,
            "power_utilization": round(power_utilization, 2) if power_utilization is not None else 0,
            "total_supplied": pin_sum,
            "total_drawn": pout_sum,
            "pue": round(pue, 4) if pue is not None else 0,
        })
        return data

    except Exception as e:
        print(f"Error querying InfluxDB for {apic_ip}: {e}")


# def get_24hDevice_power(apic_ip: str) -> List[dict]:
#     total_drawn, total_supplied = 0, 0
#     start_range = "-1h"
#
#     query = f'''
#           from(bucket: "Dcs_db")
#            |> range(start: {start_range})
#            |> filter(fn: (r) => r["_measurement"] == "DevicePSU" and r["ApicController_IP"] == "{apic_ip}")
#            |> filter(fn: (r) => r["_field"] == "total_PIn" or r["_field"] == "total_POut")
#             | > sum()
#             | > yield (name: "sum")
#                '''
#     # result = query_api.query(query)
#     try:
#         result = query_api.query_data_frame(query)
#
#         # result = result.drop_duplicates(subset=['_time', 'ApicController_IP'], keep='last')
#         print(type(result))
#
#         data = []
#         pin_sum,pout_sum=0,0
#         if not result.empty:
#             pin_sum = result['total_PIn'] if 'total_PIn' in result else 0.0
#             pout_sum = result['total_POut'] if 'total_POut' in result else 0.0
#         result = query_api.query(query)
#
#         # drawnAvg,suppliedAvg = None, None
#         #
#         # for table in result:
#         #     for record in table.records:
#         #         if record.get_field() == "total_POut":
#         #
# #         #         if drawnAvg is not None and suppliedAvg is not None:
# #         #             total_drawn += drawnAvg
# #         #             total           drawnAvg = record.get_value()
#         #         elif record.get_field() == "total_PIn":
#         #             suppliedAvg = record.get_value()
#         #_supplied += suppliedAvg
#
#         power_utilization = None
#         pue = None
#         print(pout_sum,pin_sum)
#         if pin_sum > 0:
#             power_utilization = (pout_sum / pin_sum) *100
#         if pout_sum > 0:
#             pue = (pin_sum / pout_sum)
#         if pout_sum > pin_sum:
#             pout_sum=pin_sum
#
#         data.append({
#             "apic_controller_ip": apic_ip,
#             "power_utilization": round(power_utilization, 2) if power_utilization is not None else 0,
#             "total_supplied":pin_sum,
#             "total_drawn":pout_sum,
#             "pue": round(pue, 4) if pue is not None else 0,
#            })
#         return data
#
#     except Exception as e:
#         print(f"Error querying InfluxDB for {apic_ip}: {e}")




def get_24hDevice_powerIn(apic_ip: str) -> List[dict]:

    start_range = "-24h"
    query = f'''
        from(bucket: "Dcs_db")
               |> range(start:  {start_range})
               |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
               |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
               |> aggregateWindow(every: 24h, fn: sum)
               |> yield(name: "mean_result")
        '''
    result = query_api.query(query)
    hourly_data = []
    PowerIn, PowerOut = None, None
    for table in result:
        for record in table.records:

            if record.get_field() == "total_PIn":
                PowerIn = record.get_value()
            elif record.get_field() == "total_POut":
                PowerOut = record.get_value()

            print("power", PowerOut)
            power_efficiency = None
            if PowerIn is not None and PowerOut is not None and PowerIn > 0:
                power_efficiency = (PowerOut / PowerIn) * 100
            hourly_data.append({
                "apic_controller_ip": apic_ip,
                "power_efficiency": round(power_efficiency, 2) if power_efficiency is not None else None
            })
    print(hourly_data,"dssfdsd")
    return hourly_data


def get_device_power(apic_ip) -> List[dict]:

    total_drawn, total_supplied = 0, 0
    start_range = "-2h"
    query = query = f'''from(bucket: "Dcs_db")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sum()
              |> yield(name: "total_sum")'''

    result = query_api.query(query)
    data = []
    try:
        result = query_api.query(query)

        drawnAvg, suppliedAvg = None, None

        for table in result:
            for record in table.records:
                if record.get_field() == "total_POut":
                    drawnAvg = record.get_value()
                elif record.get_field() == "total_PIn":
                    suppliedAvg = record.get_value()

                if drawnAvg is not None and suppliedAvg is not None:
                    total_drawn += drawnAvg
                    total_supplied += suppliedAvg

        power_utilization = None
        if total_supplied > 0:
            power_utilization = (total_drawn / total_supplied) * 100

        data.append({
            "apic_controller_ip": apic_ip,
            "power_utilization": round(power_utilization, 2) if power_utilization is not None else 0
        })

    except Exception as e:
        print(f"Error querying InfluxDB for {apic_ip}: {e}")
        

    return data


def get_top_data_traffic_nodes() -> List[dict]:
    start_range = "-24h"
    query = f'''
        from(bucket: "{bucket}")
        |> range(start: {start_range})
        |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic")
        |> filter(fn: (r) => r["_field"] == "total_bytesLast")
        |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
    '''
    try:
        result = query_api.query(query)
        print("RESULT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!", result, file=sys.stderr)
        data = []
        for table in result:
            for record in table.records:
                data.append({
                    "controller": record.values.get("ApicController_IP"),
                    "total_bytesLast": record.values.get("total_bytesLast"),
                })
        print(f"Fetched {len(data)} records from InfluxDB.", file=sys.stderr)
        return data
    except Exception as e:
        print(f"Failed to fetch top data traffic nodes from InfluxDB: {e}", file=sys.stderr)
        return []

def get_24hsite_power(apic_ips, site_id) -> List[dict]:
    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]
    print(apic_ip_list)
    if not apic_ip_list:
        return []
    start_range = "-24h"
    site_data = []
    total_drawn, total_supplied = 0, 0
    data_gb=0
    for apic_ip in apic_ip_list:
        print(apic_ip)
        query = f'''from(bucket: "Dcs_db")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DevicePSU")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sum()
              |> yield(name: "total_sum")'''
        try:
            result = query_api.query(query)

            drawnAvg,suppliedAvg = None, None

            for table in result:
                for record in table.records:
                    if record.get_field() == "total_POut":
                        drawnAvg = record.get_value()
                    elif record.get_field() == "total_PIn":
                        suppliedAvg = record.get_value()

                    if drawnAvg is not None and suppliedAvg is not None:
                        total_drawn += drawnAvg
                        total_supplied += suppliedAvg

            power_utilization = None
            pue=None
            if total_supplied > 0:
                power_utilization = (total_drawn / total_supplied) * 100
            if total_drawn>0:
                pue=((total_supplied / total_drawn)-1) * 100

            site_data.append({
                "site_id": site_id,
                "power_utilization": round(power_utilization, 2) if power_utilization is not None else 0,
                "power_input":total_supplied,
                "pue":round(pue, 2) if pue is not None else 0
            })

        except Exception as e:
            print(f"Error querying InfluxDB for {apic_ip}: {e}")
            

    return site_data


def get_24hsite_datatraffc(apic_ips, site_id) -> List[dict]:
    apic_ip_list = [ip[0] for ip in apic_ips if ip[0]]
    print(apic_ip_list)
    if not apic_ip_list:
        return []

    start_range = "-24h"
    site_data = []
    total_byterate=0

    for apic_ip in apic_ip_list:
        print(apic_ip)
        query = f'''from(bucket: "Dcs_db")
              |> range(start: {start_range})
              |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic")
              |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
              |> sum()
              |> yield(name: "total_sum")'''
        try:
            result = query_api.query(query)
            byterate= None

            for table in result:
                for record in table.records:
                    if record.get_field() == "total_bytesRateLast":
                        byterate = record.get_value()
                    else:
                        byterate=0
                    total_byterate += byterate
            print(total_byterate, "total_bytesRateLast")

            site_data.append({
                "site_id": site_id,
                "traffic_through": total_byterate  })
        except Exception as e:
            print(f"Error querying InfluxDB for {apic_ip}: {e}")
            

    return site_data
def get_excel_df(ip_addresses):
    # Fields to extract
    fields = [
        "total_bytesRateLast", "total_pktsRateLast",
         "total_input_bytes", "total_output_bytes",
        "total_input_packets", "total_output_packets", "bandwidth"
    ]

    # Connect to InfluxDB


    # Empty list to collect all records
    all_records = []

    for ip in ip_addresses:
        print(f"ðŸ” Fetching data for IP: {ip}")

        field_filter = " or ".join([f'r._field == "{field}"' for field in fields])


        query = f'''
        from(bucket: "Dcs_db")
          |> range(start:2025-06-02T10:04:00Z, stop: 2025-06-02T11:04:00Z)
          |> filter(fn: (r) => r._measurement == "DeviceEngreeTraffic")
          |> filter(fn: (r) => r["ApicController_IP"] == "{ip}")
          |> filter(fn: (r) => {field_filter})
          |> aggregateWindow(every: 1m, fn: last, createEmpty: false)
          |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
          |> keep(columns: ["_time", "ApicController_IP", {", ".join([f'"{f}"' for f in fields])}])
          |> sort(columns: ["_time"])
        '''

        tables = query_api.query(query)

        for table in tables:
            for record in table.records:
                row = {
                    "Time": record.get_time().replace(tzinfo=None),
                    "IP Address": record.values.get("ApicController_IP"),
                    "Total Input (MB)": round(record.values.get("total_input_bytes", 0) / (1024 * 1024), 2),
                    "Total Output (MB)": round(record.values.get("total_output_bytes", 0) / (1024 * 1024), 2),
                    "Input Packets": record.values.get("total_input_packets"),
                    "Output Packets": record.values.get("total_output_packets"),
                }
                all_records.append(row)

            # Convert to DataFrame
    df = pd.DataFrame(all_records)

    print(df)
    return df



# def get_24hDevice_dataTraffic(apic_ip: str) -> List[dict]:
#         print(f"Fetching traffic data for {apic_ip}")
#         total_traffic = 0.0
#         total_bandwidth = 0.0
#         total_output_bytes=0.0
#         total_input_bytes=0.0
#
#         start_range = "-1h"
#
#         query = f'''
#             from(bucket: "Dcs_db")
#             |> range(start: {start_range})
#             |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic" and r["ApicController_IP"] == "{apic_ip}")
#             |> filter(fn: (r) => r["_field"] == "total_bytesRateLast" or r["_field"] == "bandwidth" or r["_field"]=="total_input_bytes" or r["_field"]=="total_output_bytes")
#             |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
#             |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
#         '''
#         data = []
#         try:
#             result = query_api.query_data_frame(query)
#             result = result.drop_duplicates(subset=['_time', 'ApicController_IP'], keep='last')
#             if not result.empty:
#                 # Ensure columns exist before summing
#                 if "total_bytesRateLast" in result.columns:
#                     total_traffic = float(result["total_bytesRateLast"].sum())
#                 if "bandwidth" in result.columns:
#                     total_bandwidth = float(result["bandwidth"].sum())
#                 if "total_output_bytes" in result.columns:
#                     total_output_bytes=float(result["total_output_bytes"].sum())
#                 if "total_input_bytes" in result.columns:
#                     total_input_bytes=float(result["total_input_bytes"].sum())
#
#
#         except Exception as e:
#             print(f"Error while querying InfluxDB: {e}")
#             return [{
#                 "apic_controller_ip": apic_ip,
#                 "traffic_through": 0.0,
#                 "bandwidth": 0.0
#             }]
#         print("datatat------------------------------------------------------------")
#         print([{
#             "apic_controller_ip": apic_ip,
#             "traffic_through": total_traffic,
#             "total_output_bytes":total_output_bytes,
#             "total_input_bytes":total_input_bytes,
#             "bandwidth": total_bandwidth
#         }])
#         return [{
#             "apic_controller_ip": apic_ip,
#             "traffic_through": total_traffic,
#             "total_output_bytes":total_output_bytes,
#             "total_input_bytes":total_input_bytes,
#             "bandwidth": total_bandwidth
#         }]
#

from typing import List
def start_end_date(start_date, end_date):
    if start_date and end_date:
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        delta_days = (end_dt - start_dt).days
        if delta_days <= 1:
            window_every = "1h"
            date_format = "%Y-%m-%d %H:00"
        elif delta_days <= 31:
            window_every = "1d"
            date_format = "%Y-%m-%d"
        else:
            window_every = "1mo"
            date_format = "%Y-%m"
        return window_every, date_format, delta_days

    else:
        raise ValueError("Provide either duration_str or both start_date and end_date.")


def get_24hDevice_dataTraffic(apic_ip: str) -> List[dict]:
    print(f"Fetching traffic data for {apic_ip}")

    # Initialize totals
    total_traffic = 0.0
    total_bandwidth = 0.0
    total_output_bytes = 0.0
    total_input_bytes = 0.0
    total_output_rate = 0.0
    total_input_rate = 0.0
    total_input_packets = 0.0
    total_output_packets = 0.0

    start_range = "-1h"

    query = f'''
        from(bucket: "Dcs_db")
        |> range(start:{start_range})
        |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic" and r["ApicController_IP"] == "{apic_ip}")
        |> filter(fn: (r) =>
            r["_field"] == "total_bytesRateLast" or
            r["_field"] == "bandwidth" or
            r["_field"] == "total_input_bytes" or
            r["_field"] == "total_output_bytes" or
            r["_field"] == "total_output_rate" or
            r["_field"] == "total_input_rate" or
            r["_field"] == "total_input_packets" or
            r["_field"] == "total_output_packets"
        )
        |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
        |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
        
    '''

    data = []
    try:
        result = query_api.query_data_frame(query)
        result = result.drop_duplicates(subset=['_time', 'ApicController_IP'], keep='last')

        if not result.empty:
            if "bandwidth" in result.columns:
                bandwidth_series = result["bandwidth"].dropna()
                total_bandwidth = float(bandwidth_series.iloc[-1]) if not bandwidth_series.empty else 0.0
            else:
                total_bandwidth = 0.0
            # Safely sum available columns
            total_traffic = float(result.get("total_bytesRateLast", 0).sum())
            total_bandwidth = total_bandwidth
            total_output_bytes = float(result.get("total_output_bytes", 0).sum())
            total_input_bytes = float(result.get("total_input_bytes", 0).sum())
            total_output_rate = float(result.get("total_output_rate", 0).sum())
            total_input_rate = float(result.get("total_input_rate", 0).sum())
            total_input_packets = float(result.get("total_input_packets", 0).sum())
            total_output_packets = float(result.get("total_output_packets", 0).sum())

    except Exception as e:
        print(f"Error while querying InfluxDB: {e}")
        return 0

    # Print and return the result
    traffic_data = {
        "apic_controller_ip": apic_ip,
        "traffic_through": total_traffic,
        "total_output_bytes": total_output_bytes,
        "total_input_bytes": total_input_bytes,
        "total_output_rate": total_output_rate,
        "total_input_rate": total_input_rate,
        "total_input_packets": total_input_packets,
        "total_output_packets": total_output_packets,
        "bandwidth": total_bandwidth
    }

    print("Traffic data summary ------------------------------------------------------------")
    print(traffic_data)

    return [traffic_data]


# def get_24hDevice_dataTraffic(apic_ip: str) -> List[dict]:
#     print(apic_ip)
#     total_traffic= 0
#     total_bandwidth=0
#     start_range = "-24h"
#     query = f'''from(bucket: "Dcs_db")
#               |> range(start: {start_range})
#               |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic")
#               |> filter(fn: (r) => r["ApicController_IP"] == "{apic_ip}")
#               |> sum()
#               |> yield(name: "total_sum")'''
#     data = []
#     query = f'''
#                 from(bucket: "Dcs_db")
#               |> range(start: {start_range})
#                    |> filter(fn: (r) => r["_measurement"] == "DeviceEngreeTraffic" and r["ApicController_IP"] == "{apic_ip}")
#                    |> filter(fn: (r) => r["_field"] == "total_bytesRateLast"or r["_field"] == "bandwidth")
#                    |> aggregateWindow(every: 1h, fn: sum, createEmpty: false)
#                '''
#     try:
#         result = query_api.query_data_frame(query)
#         data = []
#         pin_sum,pout_sum=0,0
#         if not result.empty:
#             total_traffic = result['total_bytesRateLast'].sum() if 'total_bytesRateLast' in result else 0.0
#             total_bandwidth = result['bandwidth'].sum() if 'bandwidth' in result else 0.0
#     # result = query_api.query_data_frame(query)
#     # if not result.empty:
#     #     datatraffic += result['_value'].sum()
#     # try:
#     #     result = query_api.query(query)
#     #     Totalbytes ,bandwidth= None,None
#     #
#     #     for table in result:
#     #         for record in table.records:
#     #             # field=record.get_field()
#     #             if record.get_field() == "total_bytesRateLast":
#     #                 Totalbytes = record.get_value()
#     #             else:
#     #                 Totalbytes =0
#     #             if record.get_field() == "bandwidth":
#     #                 bandwidth = record.get_value()
#     #             else:
#     #                 bandwidth =0
#     #             if Totalbytes is not None:
#     #                 total_traffic += Totalbytes
#     #             if bandwidth is not None:
#     #                 total_bandwidth+=bandwidth
#         print("herewwsd;allllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll")
#         data.append({
#             "apic_controller_ip": apic_ip,
#             "traffic_through":  total_traffic,
#             "bandwidth":total_bandwidth
#            })
#
#     except Exception as e:
#         print(f"Error querying InfluxDB for {apic_ip}: {e}")
#
#     print(data)

    # return data
def get_all_vm(hostname) -> List[dict]:

    query = f'''
   from(bucket: "Dcs_db")
  |> range(start: -1h)
  |> filter(fn: (r) => r["_measurement"] == "Final_vm_stats")
  |> filter(fn: (r) => r["hostname"] == "{hostname}")
  |> mean()
  |> yield(name: "average")
    '''

    result = query_api.query(query)
    data = []
    used_space,used_cpu,used_memory,cpu_usage_percent,memory_usage_percent=None,None,None,None,None
    try:
        result = query_api.query(query)

        for table in result:
            for record in table.records:
                if record.get_field() == "used_space_GB":
                    used_space = record.get_value()
                elif record.get_field() == "used_cpu_MHz":
                    used_cpu = record.get_value()

                elif record.get_field() == "used_memory_MB":
                    used_memory = record.get_value()
                elif record.get_field() == "cpu_usage_percent":
                    cpu_usage_percent = record.get_value()
                elif record.get_field() == "memory_usage_percent":
                    memory_usage_percent = record.get_value()

        data.append({
            "hostname": hostname,
            "used_space_GB":used_space,
            "used_cpu_MHz":used_cpu,
            "used_memory_MB":used_memory,
            "memory_usage_percent":memory_usage_percent,
            "cpu_usage_percent":cpu_usage_percent
         })

    except Exception as e:
        print(f"Error querying InfluxDB for {hostname}: {e}")
        

    return data
def get_24_vm_stoage(hostname: str) -> List[dict]:
    
    query = f'''
        from(bucket: "{bucket}")
        |> range(start: -24h)
        |> filter(fn: (r) => r["_measurement"] == "Final_vm_stats")
        |> filter(fn: (r) => r["hostname"] == "{hostname}")
        |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
        |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
    '''
    results = query_api.query(query)

    
    hourly_data = {}
    now = datetime.datetime.utcnow()
    for i in range(24):
        hour =  (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
        hourly_data[hour] = {
            "hostname": hostname,
            "hour": hour,
            "Used_space_GB": 0,
        }

    
    for table in results:
        for record in table.records:
            hour = record.get_time().strftime('%Y-%m-%d %H:00')
            hourly_data[hour].update({
                "Used_space_GB": record.values.get('used_space_GB', 0),
            })

    
    hourly_data_list = sorted(hourly_data.values(), key=lambda x: x["hour"], reverse=True)
    return hourly_data_list


def get_24_vm_usage(hostname: str) -> List[dict]:
    
    query = f'''
        from(bucket: "{bucket}")
        |> range(start: -24h)
        |> filter(fn: (r) => r["_measurement"] == "Final_vm_stats")
        |> filter(fn: (r) => r["hostname"] == "{hostname}")
        |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
        |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
    '''
    results = query_api.query(query)

    
    hourly_data = {}
    now = datetime.datetime.utcnow()
    for i in range(24):
        hour =  (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
        hourly_data[hour] = {
            "hostname": hostname,
            "hour": hour,
            "mem_usage_gb": 0,
            "cpu_usage_percent": 0,
            "cpu_ready_percent": 0
        }

    
    for table in results:
        for record in table.records:
            hour = record.get_time().strftime('%Y-%m-%d %H:00')
            hourly_data[hour].update({
                "mem_usage_gb": record.values.get('mem_usage_gb', 0),
                "cpu_usage_percent": record.values.get('cpu_usage_percent', 0),
                "cpu_ready_percent": record.values.get('cpu_ready_percent', 0)
            })

    
    hourly_data_list = sorted(hourly_data.values(), key=lambda x: x["hour"], reverse=True)
    return hourly_data_list


def get_24_host_storage(hostname: str) -> List[dict]:
    
    print("we are here")
    query = f'''
           from(bucket: "Dcs_db")
              |> range(start: -24h, stop: now())
              |> filter(fn: (r) => r["_measurement"] == "host_usage")
              |> filter(fn: (r) => r["_field"] == "used_storage_gb")
              |> filter(fn: (r) => r["host_name"] == "{hostname}")
              |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
              |> yield(name: "mean")

       '''
    try:
        results = query_api.query(query)
    except Exception as e:
        print(f"Error querying InfluxDB: {e}")
        return []
    hourly_data = {}
    if results:

        now = datetime.datetime.utcnow()
        for i in range(24):
            hour = (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
            hourly_data[hour] = {
                "hostname": hostname,
                "hour": hour,
                "used_space_GB": 0,
            }

        for table in results:
            for record in table.records:
                hour = record.get_time().strftime('%Y-%m-%d %H:00')
                print()
                if hour in hourly_data:
                    hourly_data[hour]["used_space_GB"] = record.get_value()


    else:
        print("No hourly data")
    hourly_data_list = sorted(hourly_data.values(), key=lambda x: x["hour"], reverse=True)
    return hourly_data_list


def get_24_host_usage(hostname: str) -> List[dict]:
    
    query = f'''
       from(bucket: "Dcs_db")
  |> range(start: -24h)
  |> filter(fn: (r) => r["_measurement"] == "host_usage")
  |> filter(fn: (r) => r["host_name"] == "{hostname}")
    |> filter(fn: (r) => r["_field"] == "powerInput" or r["_field"] == "powerOutput" or r["_field"] == "used_memory_gb" or r["_field"] == "cpu_usage_percent")
 |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")


    '''
    results = query_api.query(query)

    
    hourly_data = {}
    if results:
        now = datetime.datetime.utcnow()
        for i in range(24):
            hour = (now - datetime.timedelta(hours=i)).strftime('%Y-%m-%d %H:00')
            hourly_data[hour] = {
                "hostname": hostname,
                "hour": hour,
                "mem_usage_gb": 0,
                "cpu_usage_percent": 0,
                "EER": 0,
                "PUE": 0
            }

            
        powerutilization, pue = 0, 0
        for table in results:
            for record in table.records:
                powerOutput = record.values.get('powerOutput')
                powerInput = record.values.get('powerInput')

                if powerInput is not None:
                    powerutilization = (powerOutput / powerInput) * 100
                if powerOutput is not None:
                    pue = ((powerInput / powerOutput) - 1) * 100
                hour = record.get_time().strftime('%Y-%m-%d %H:00')

                hourly_data[hour].update({
                    "mem_usage_gb": record.values.get('used_memory_gb', 0),
                    "cpu_usage_percent": record.values.get('cpu_usage_percent', 0),
                    "EER": powerutilization,
                    "PUE": pue

                })

        
    else:
        print("no data available")
    hourly_data_list = sorted(hourly_data.values(), key=lambda x: x["hour"], reverse=True)

    return hourly_data_list


def get_all_hostutilizaton(hostname) -> List[dict]:
    query = f'''
  from(bucket: "Dcs_db")
  |> range(start:-24h)
  |> filter(fn: (r) => r["_measurement"] == "host_usage")
  |> filter(fn: (r) => r["host_name"] == "localhost")
  |> filter(fn: (r) => r["_field"] != "uptime") // Exclude known string fields
  |>mean()
  |> yield(name: "mean")
       '''
    data = []
    try:
        result = query_api.query(query)
        if result:
            host_info = {}
    
            for table in result:
                for record in table.records:
                    field_name = record.get_field()
                    value = record.get_value()
                    host_info[field_name] = round(value, 2)
    
            
            host_info["hostname"] = hostname
            data.append(host_info)
        else:
            print("no data")

    except Exception as e:
        print(f"Error querying InfluxDB for {hostname}: {e}")

    return data